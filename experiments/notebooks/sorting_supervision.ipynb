{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "AlgoVisionMNISTExperiment.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "48cdea7effb44a3fa3f58fd4458c037d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HBoxView",
      "_dom_classes": [],
      "_model_name": "HBoxModel",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "box_style": "",
      "layout": "IPY_MODEL_07770b0cd2874d5393a3dced3a91d389",
      "_model_module": "@jupyter-widgets/controls",
      "children": [
       "IPY_MODEL_9c638cd63b034656a485828e3c73731e",
       "IPY_MODEL_73973d5cd5db46e790afc33136f6b28d",
       "IPY_MODEL_a7d0c082380d4fd28f623adc495fee63"
      ]
     }
    },
    "07770b0cd2874d5393a3dced3a91d389": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "9c638cd63b034656a485828e3c73731e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_d54dfa3281ee4e36aa3f2f54f96c3069",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": "Training steps:   0%",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_ac455016cd484af7b2dc298e39f33aea"
     }
    },
    "73973d5cd5db46e790afc33136f6b28d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "ProgressView",
      "style": "IPY_MODEL_6823154ac2894f308cfb60a1d45cc267",
      "_dom_classes": [],
      "description": "",
      "_model_name": "FloatProgressModel",
      "bar_style": "danger",
      "max": 1000000,
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": 1304,
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "orientation": "horizontal",
      "min": 0,
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_15a4b32e7765417caa33f2cdbdad1e28"
     }
    },
    "a7d0c082380d4fd28f623adc495fee63": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "HTMLView",
      "style": "IPY_MODEL_e3212353509145e58b71cd10e1e1a831",
      "_dom_classes": [],
      "description": "",
      "_model_name": "HTMLModel",
      "placeholder": "​",
      "_view_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "value": " 1304/1000000 [04:09&lt;37:14:44,  7.45it/s]",
      "_view_count": null,
      "_view_module_version": "1.5.0",
      "description_tooltip": null,
      "_model_module": "@jupyter-widgets/controls",
      "layout": "IPY_MODEL_ed2dd98bf21749d68dee30057ecb05b9"
     }
    },
    "d54dfa3281ee4e36aa3f2f54f96c3069": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "ac455016cd484af7b2dc298e39f33aea": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "6823154ac2894f308cfb60a1d45cc267": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "ProgressStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "bar_color": null,
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "15a4b32e7765417caa33f2cdbdad1e28": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    },
    "e3212353509145e58b71cd10e1e1a831": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_view_name": "StyleView",
      "_model_name": "DescriptionStyleModel",
      "description_width": "",
      "_view_module": "@jupyter-widgets/base",
      "_model_module_version": "1.5.0",
      "_view_count": null,
      "_view_module_version": "1.2.0",
      "_model_module": "@jupyter-widgets/controls"
     }
    },
    "ed2dd98bf21749d68dee30057ecb05b9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_view_name": "LayoutView",
      "grid_template_rows": null,
      "right": null,
      "justify_content": null,
      "_view_module": "@jupyter-widgets/base",
      "overflow": null,
      "_model_module_version": "1.2.0",
      "_view_count": null,
      "flex_flow": null,
      "width": null,
      "min_width": null,
      "border": null,
      "align_items": null,
      "bottom": null,
      "_model_module": "@jupyter-widgets/base",
      "top": null,
      "grid_column": null,
      "overflow_y": null,
      "overflow_x": null,
      "grid_auto_flow": null,
      "grid_area": null,
      "grid_template_columns": null,
      "flex": null,
      "_model_name": "LayoutModel",
      "justify_items": null,
      "grid_row": null,
      "max_height": null,
      "align_content": null,
      "visibility": null,
      "align_self": null,
      "height": null,
      "min_height": null,
      "padding": null,
      "grid_auto_rows": null,
      "grid_gap": null,
      "max_width": null,
      "order": null,
      "_view_module_version": "1.2.0",
      "grid_template_areas": null,
      "object_position": null,
      "object_fit": null,
      "grid_auto_columns": null,
      "margin": null,
      "display": null,
      "left": null
     }
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T9yKt7coQGZt"
   },
   "source": [
    "# Sorting Supervision Experiment\n",
    "\n",
    "If possible, you should run it with a GPU instance by going to `Runtime` -> `Change runtime type` -> `Hardware Accelerator` -> `GPU`.\n",
    "\n",
    "* Paper: https://arxiv.org/abs/2110.05651\n",
    "* Video: https://www.youtube.com/watch?v=01ENzpkjOCE\n",
    "* Code: https://github.com/Felix-Petersen/algovision\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5vhGNO5xOFsI",
    "outputId": "c893a3d7-99f8-43c7-83af-dc7bd3618103"
   },
   "source": [
    "!pip install algovision"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting algovision\n",
      "  Downloading algovision-0.1.0-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from algovision) (1.19.5)\n",
      "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from algovision) (1.10.0+cu111)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.9.0->algovision) (3.10.0.2)\n",
      "Installing collected packages: algovision\n",
      "Successfully installed algovision-0.1.0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form",
    "id": "Qi9Is8mlOH6s"
   },
   "source": [
    "#@title Data set definition\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class MultiDigitDataset(Dataset):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            images,\n",
    "            labels,\n",
    "            num_digits,\n",
    "            num_compare,\n",
    "            seed=0,\n",
    "            determinism=True,\n",
    "    ):\n",
    "        super(MultiDigitDataset, self).__init__()\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.num_digits = num_digits\n",
    "        self.num_compare = num_compare\n",
    "        self.seed = seed\n",
    "        self.rand_state = None\n",
    "\n",
    "        self.determinism = determinism\n",
    "\n",
    "        if determinism:\n",
    "            self.reset_rand_state()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.images.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        if self.determinism:\n",
    "            prev_state = torch.random.get_rng_state()\n",
    "            torch.random.set_rng_state(self.rand_state)\n",
    "\n",
    "        labels = []\n",
    "        images = []\n",
    "        labels_ = None\n",
    "        for digit_idx in range(self.num_digits):\n",
    "            id = torch.randint(len(self), (self.num_compare, ))\n",
    "            labels.append(self.labels[id])\n",
    "            images.append(self.images[id].type(torch.float32) / 255.)\n",
    "            if labels_ is None:\n",
    "                labels_ = torch.zeros_like(labels[0] * 1.)\n",
    "            labels_ = labels_ + 10.**(self.num_digits - 1 - digit_idx) * self.labels[id]\n",
    "\n",
    "        images = torch.cat(images, dim=-1)\n",
    "\n",
    "        if self.determinism:\n",
    "            self.rand_state = torch.random.get_rng_state()\n",
    "            torch.random.set_rng_state(prev_state)\n",
    "\n",
    "        return images, labels_\n",
    "\n",
    "    def reset_rand_state(self):\n",
    "        prev_state = torch.random.get_rng_state()\n",
    "        torch.random.manual_seed(self.seed)\n",
    "        self.rand_state = torch.random.get_rng_state()\n",
    "        torch.random.set_rng_state(prev_state)\n",
    "\n",
    "\n",
    "class MultiDigitSplits(object):\n",
    "    def __init__(self, dataset, num_digits=4, num_compare=None, seed=0, deterministic_data_loader=True):\n",
    "\n",
    "        self.deterministic_data_loader = deterministic_data_loader\n",
    "\n",
    "        if dataset == 'mnist':\n",
    "            trva_real = datasets.MNIST(root='./data-mnist', download=True)\n",
    "            xtr_real = trva_real.data[:55000].view(-1, 1, 28, 28)\n",
    "            ytr_real = trva_real.targets[:55000]\n",
    "            xva_real = trva_real.data[55000:].view(-1, 1, 28, 28)\n",
    "            yva_real = trva_real.targets[55000:]\n",
    "\n",
    "            te_real = datasets.MNIST(root='./data-mnist', train=False, download=True)\n",
    "            xte_real = te_real.data.view(-1, 1, 28, 28)\n",
    "            yte_real = te_real.targets\n",
    "\n",
    "            self.train_dataset = MultiDigitDataset(\n",
    "                images=xtr_real, labels=ytr_real, num_digits=num_digits, num_compare=num_compare, seed=seed,\n",
    "                determinism=deterministic_data_loader)\n",
    "            self.valid_dataset = MultiDigitDataset(\n",
    "                images=xva_real, labels=yva_real, num_digits=num_digits, num_compare=num_compare, seed=seed)\n",
    "            self.test_dataset = MultiDigitDataset(\n",
    "                images=xte_real, labels=yte_real, num_digits=num_digits, num_compare=num_compare, seed=seed)\n",
    "\n",
    "        elif dataset == 'svhn':\n",
    "            self.train_dataset = SVHNMultiDigit(root='./data-svhn', split='train', download=True)\n",
    "            self.valid_dataset = SVHNMultiDigit(root='./data-svhn', split='val', download=True)\n",
    "            self.test_dataset = SVHNMultiDigit(root='./data-svhn', split='test', download=True)\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "\n",
    "    def get_train_loader(self, batch_size, **kwargs):\n",
    "        train_loader = DataLoader(self.train_dataset,\n",
    "                                  batch_size=batch_size,\n",
    "                                  num_workers=4 if not self.deterministic_data_loader else 0,\n",
    "                                  shuffle=True, **kwargs)\n",
    "        return train_loader\n",
    "\n",
    "    def get_valid_loader(self, batch_size, **kwargs):\n",
    "        valid_loader = DataLoader(self.valid_dataset,\n",
    "                                  batch_size=batch_size, shuffle=False, **kwargs)\n",
    "        return valid_loader\n",
    "\n",
    "    def get_test_loader(self, batch_size, **kwargs):\n",
    "        test_loader = DataLoader(self.test_dataset,\n",
    "                                 batch_size=batch_size, shuffle=False, **kwargs)\n",
    "        return test_loader\n"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hH0pXLjaOLqD",
    "cellView": "form"
   },
   "source": [
    "#@title Utils definition\n",
    "\n",
    "import collections\n",
    "import functools\n",
    "import operator\n",
    "\n",
    "\n",
    "def avg_list_of_dicts(list_of_dicts):\n",
    "    summed = functools.reduce(operator.add, map(collections.Counter, list_of_dicts))\n",
    "    averaged = {k: summed[k] / len(list_of_dicts) for k in summed}\n",
    "    return averaged\n",
    "\n",
    "def load_n(loader, n):\n",
    "    i = 0\n",
    "    while i < n:\n",
    "        for x in loader:\n",
    "            yield x\n",
    "            i += 1\n",
    "            if i == n:\n",
    "                break"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "A0HgVOjLOMNk"
   },
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class MultiDigitMNISTNet(nn.Module):\n",
    "    def __init__(self, n_digits=4):\n",
    "        super(MultiDigitMNISTNet, self).__init__()\n",
    "        self.n_digits = n_digits\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5, 1, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5, 1, 2)\n",
    "        self.fc1 = nn.Linear(n_digits * 7 * 7 * 64, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_shape = x.shape\n",
    "        if len(x_shape) == 5:\n",
    "            x = x.reshape(-1, *x_shape[2:])\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, self.n_digits * 7 * 7 * 64)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = x.reshape(*x_shape[:2], 1)\n",
    "        return x"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HOGuOOvcOzEf"
   },
   "source": [
    "def ranking_accuracy(data, targets):\n",
    "    scores = model(data).squeeze(2)\n",
    "\n",
    "    acc = torch.argsort(targets, dim=-1) == torch.argsort(scores, dim=-1)\n",
    "\n",
    "    acc_em = acc.all(-1).float().mean()\n",
    "    acc_ew = acc.float().mean()\n",
    "\n",
    "    # EM5:\n",
    "    scores = scores[:, :5]\n",
    "    targets = targets[:, :5]\n",
    "    acc = torch.argsort(targets, dim=-1) == torch.argsort(scores, dim=-1)\n",
    "    acc_em5 = acc.all(-1).float().mean()\n",
    "\n",
    "    return dict(\n",
    "        acc_em=acc_em.type(torch.float32).mean().item(),\n",
    "        acc_ew=acc_ew.type(torch.float32).mean().item(),\n",
    "        acc_em5=acc_em5.type(torch.float32).mean().item(),\n",
    "    )"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 657,
     "referenced_widgets": [
      "48cdea7effb44a3fa3f58fd4458c037d",
      "07770b0cd2874d5393a3dced3a91d389",
      "9c638cd63b034656a485828e3c73731e",
      "73973d5cd5db46e790afc33136f6b28d",
      "a7d0c082380d4fd28f623adc495fee63",
      "d54dfa3281ee4e36aa3f2f54f96c3069",
      "ac455016cd484af7b2dc298e39f33aea",
      "6823154ac2894f308cfb60a1d45cc267",
      "15a4b32e7765417caa33f2cdbdad1e28",
      "e3212353509145e58b71cd10e1e1a831",
      "ed2dd98bf21749d68dee30057ecb05b9"
     ]
    },
    "id": "Nb34SYcLO4IQ",
    "outputId": "84c6f59a-23d6-4139-bf6d-259212d449f7"
   },
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "import torch\n",
    "from algovision import (\n",
    "    Algorithm, Input, Output, Variable, Var, VariableInt, VarInt,               # core\n",
    "    Eq, NEq, LT, LEq, GT, GEq, CatProbEq, CosineSimilarity, IsTrue, IsFalse,    # conditions\n",
    "    If, While, For,                                                             # control_structures\n",
    "    Let, LetInt, Print, Min, ArgMin, Max, ArgMax,                               # functions\n",
    ")\n",
    "\n",
    "class Args:\n",
    "    batch_size = 100\n",
    "    num_compare = 5\n",
    "    num_steps = 1_000_000\n",
    "    eval_freq = 200\n",
    "    method = 'loss_sum'\n",
    "    beta = 8\n",
    "    dataset = 'mnist'\n",
    "    nloglr = 3.5\n",
    "    device = 'cuda'\n",
    "    seed = 0\n",
    "\n",
    "args = Args()\n",
    "\n",
    "random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "best_valid_acc = 0.\n",
    "\n",
    "# ---\n",
    "\n",
    "if args.device == 'cuda' and not torch.cuda.is_available():\n",
    "    print('----------------------------------------------------')\n",
    "    print('--- WARNING: No GPU detected, running on CPU ... ---')\n",
    "    print('----------------------------------------------------')\n",
    "    args.device = 'cpu'\n",
    "\n",
    "splits = MultiDigitSplits(dataset=args.dataset, num_compare=args.num_compare, seed=args.seed)\n",
    "\n",
    "# drop_last needs to be true, otherwise error with testing for SVHN\n",
    "data_loader_train = splits.get_train_loader(\n",
    "    args.batch_size, drop_last=True\n",
    ")\n",
    "data_loader_valid = splits.get_valid_loader(\n",
    "    args.batch_size, drop_last=True\n",
    ")\n",
    "data_loader_test = splits.get_test_loader(\n",
    "    args.batch_size, drop_last=True\n",
    ")\n",
    "\n",
    "if args.dataset == 'mnist':\n",
    "    model = MultiDigitMNISTNet().to(args.device)\n",
    "elif args.dataset == 'svhn':\n",
    "    model = SVHNConvNet().to(args.device)\n",
    "else:\n",
    "    raise ValueError(args.dataset)\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr=10**(-args.nloglr))\n",
    "\n",
    "bubble_sort = Algorithm(\n",
    "    Input('array'),\n",
    "\n",
    "    Var('a', torch.tensor(0.).to(args.device)),\n",
    "    Var('b', torch.tensor(0.).to(args.device)),\n",
    "    Var('swapped', torch.tensor(1.).to(args.device)),\n",
    "    Var('loss_prod', torch.tensor(0.).to(args.device)),\n",
    "    Var('loss_sum', torch.tensor(0.).to(args.device)),\n",
    "    VarInt('j', 0),\n",
    "    VarInt('n', lambda array: array.shape[1] - 1),\n",
    "    While(IsTrue('swapped'),\n",
    "            Let('swapped', 0),\n",
    "            For('i', 'n',\n",
    "                LetInt('j', lambda i: i + 1),\n",
    "                Let('a', 'array', ['i']),\n",
    "                Let('b', 'array', ['j']),\n",
    "                # Alternative notation for the two three lines above:\n",
    "                # Let('a', lambda array, i: array[:, i]),\n",
    "                # Let('b', lambda array, i: array[:, i+1]),\n",
    "                If(GT('a', 'b'),\n",
    "                    if_true=[\n",
    "                        Let('array', [lambda i: i + 1], 'a'),\n",
    "                        Let('array', ['i'], 'b'),\n",
    "                        Let('swapped', lambda swapped: 1.),\n",
    "                        Let('loss_prod', 1.),\n",
    "                        Let('loss_sum', lambda loss_sum: loss_sum + 1.),\n",
    "                    ]\n",
    "                    ),\n",
    "                ),\n",
    "            LetInt('n', lambda n: n - 1),\n",
    "            ),\n",
    "    Output('array'),\n",
    "    Output('loss_prod'),\n",
    "    Output('loss_sum'),\n",
    "    beta=args.beta,\n",
    ")\n",
    "\n",
    "valid_accs = []\n",
    "test_acc = None\n",
    "\n",
    "for iter_idx, (data, targets) in tqdm(\n",
    "    enumerate(load_n(data_loader_train, args.num_steps)),\n",
    "    desc=\"Training steps\",\n",
    "    total=args.num_steps,\n",
    "):\n",
    "    data = data.to(args.device)\n",
    "    targets = targets.to(args.device)\n",
    "\n",
    "    data_sorted = data[torch.arange(args.batch_size).to(args.device).unsqueeze(1), torch.argsort(targets, dim=-1)]\n",
    "\n",
    "    outputs = model(data_sorted).squeeze(2)\n",
    "    _, loss_prod, loss_sum = bubble_sort(outputs)\n",
    "\n",
    "    if args.method == 'loss_sum':\n",
    "        loss = loss_sum.mean()\n",
    "    elif args.method == 'loss_prod':\n",
    "        loss = loss_prod.mean()\n",
    "    else:\n",
    "        assert False, args.method\n",
    "\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "    if (iter_idx + 1) % args.eval_freq == 0:\n",
    "\n",
    "        current_valid_accs = []\n",
    "        for data, targets in data_loader_valid:\n",
    "            data, targets = data.to(args.device), targets.to(args.device)\n",
    "            current_valid_accs.append(ranking_accuracy(data, targets))\n",
    "        valid_accs.append(avg_list_of_dicts(current_valid_accs))\n",
    "\n",
    "        print(iter_idx, 'valid', valid_accs[-1])\n",
    "\n",
    "        if valid_accs[-1]['acc_em5'] > best_valid_acc:\n",
    "            best_valid_acc = valid_accs[-1]['acc_em5']\n",
    "\n",
    "            current_test_accs = []\n",
    "            for data, targets in data_loader_test:\n",
    "                data, targets = data.to(args.device), targets.to(args.device)\n",
    "                current_test_accs.append(ranking_accuracy(data, targets))\n",
    "            test_acc = avg_list_of_dicts(current_test_accs)\n",
    "\n",
    "            print(iter_idx, 'test', test_acc)\n",
    "\n",
    "print('final test', test_acc)"
   ],
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48cdea7effb44a3fa3f58fd4458c037d",
       "version_minor": 0,
       "version_major": 2
      },
      "text/plain": [
       "Training steps:   0%|          | 0/1000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "199 valid {'acc_em': 0.27119999289512636, 'acc_ew': 0.6058800303936005, 'acc_em5': 0.27119999289512636}\n",
      "199 test {'acc_em': 0.24119999378919602, 'acc_ew': 0.5792800271511078, 'acc_em5': 0.24119999378919602}\n",
      "399 valid {'acc_em': 0.2863999933004379, 'acc_ew': 0.6100400280952454, 'acc_em5': 0.2863999933004379}\n",
      "399 test {'acc_em': 0.2627999937534332, 'acc_ew': 0.597240030169487, 'acc_em5': 0.2627999937534332}\n",
      "599 valid {'acc_em': 0.308599993288517, 'acc_ew': 0.6330000340938569, 'acc_em5': 0.308599993288517}\n",
      "599 test {'acc_em': 0.291099993288517, 'acc_ew': 0.6188800275325775, 'acc_em5': 0.291099993288517}\n",
      "799 valid {'acc_em': 0.3149999928474426, 'acc_ew': 0.6386800301074982, 'acc_em5': 0.3149999928474426}\n",
      "799 test {'acc_em': 0.30759999215602873, 'acc_ew': 0.630760029554367, 'acc_em5': 0.30759999215602873}\n",
      "999 valid {'acc_em': 0.31779999285936356, 'acc_ew': 0.6437200272083282, 'acc_em5': 0.31779999285936356}\n",
      "999 test {'acc_em': 0.30809999257326126, 'acc_ew': 0.6352600306272507, 'acc_em5': 0.30809999257326126}\n",
      "1199 valid {'acc_em': 0.3405999928712845, 'acc_ew': 0.6602400290966034, 'acc_em5': 0.3405999928712845}\n",
      "1199 test {'acc_em': 0.32269999280571937, 'acc_ew': 0.6436400324106216, 'acc_em5': 0.32269999280571937}\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-8-275d2c824f97>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[1;32m    108\u001B[0m     \u001B[0mdata_sorted\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0marange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munsqueeze\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0margsort\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtargets\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdim\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    109\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 110\u001B[0;31m     \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata_sorted\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msqueeze\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    111\u001B[0m     \u001B[0m_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mloss_prod\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mloss_sum\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbubble_sort\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moutputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    112\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1103\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-4-506de7bdc66a>\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     17\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx_shape\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m5\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     18\u001B[0m             \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0mx_shape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 19\u001B[0;31m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrelu\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconv1\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     20\u001B[0m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmax_pool2d\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m2\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     21\u001B[0m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrelu\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconv2\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1103\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    444\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    445\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 446\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_conv_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbias\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    447\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    448\u001B[0m \u001B[0;32mclass\u001B[0m \u001B[0mConv3d\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_ConvNd\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001B[0m in \u001B[0;36m_conv_forward\u001B[0;34m(self, input, weight, bias)\u001B[0m\n\u001B[1;32m    441\u001B[0m                             _pair(0), self.dilation, self.groups)\n\u001B[1;32m    442\u001B[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001B[0;32m--> 443\u001B[0;31m                         self.padding, self.dilation, self.groups)\n\u001B[0m\u001B[1;32m    444\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    445\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7Wp-dlvtPHbF"
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}